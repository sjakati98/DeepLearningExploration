{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Lambda, Dense, Conv2D, Conv2DTranspose, MaxPool2D, Flatten, Reshape, Layer\n",
    "from keras.models import Model\n",
    "from keras import metrics\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 50\n",
    "image_size = (28,28,1)\n",
    "latent_dimension = 3 ## to view representation clusters in 3 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## defining the input for mnist images\n",
    "input_image = Input(shape=image_size, name='encoder_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## defining the inference network\n",
    "## this is the network that will produce a latent space representation of the original image\n",
    "## 5 layer convolutional network\n",
    "encoder = Conv2D(16, (3,3), activation='relu', padding='same', name=\"encoder_conv1\")(input_image)\n",
    "encoder = MaxPool2D((2,2), padding=\"same\", name=\"encoder_pool1\")(encoder)\n",
    "encoder = Conv2D(8, (3,3), activation='relu', padding='same', name=\"encoder_conv2\")(encoder)\n",
    "encoder = MaxPool2D((2,2), padding=\"same\", name=\"encoder_pool2\")(encoder)\n",
    "encoder = Conv2D(4, (3,3), activation='relu', padding='same', name=\"encoder_conv3\")(encoder)\n",
    "encoder_shape = K.int_shape(encoder)\n",
    "encoder = Flatten()(encoder) ## turns output to size of (None, 196)\n",
    "encoder = Dense(32, activation='relu')(encoder)\n",
    "\n",
    "z_mean = Dense(latent_dimension, name=\"z_mean\")(encoder)\n",
    "z_var = Dense(latent_dimension, name=\"z_var\")(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining the sampling method for the generator network\n",
    "def normal_sample(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dimension),\n",
    "                              mean=0., stddev=1.)\n",
    "    return z_mean + K.exp(z_log_var) * epsilon\n",
    "z = Lambda(normal_sample, name=\"z_sample\", output_shape=(latent_dimension,))([z_mean, z_var])\n",
    "encoder = Model(input_image, [z_mean, z_var, z], name='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## building decoder model\n",
    "\n",
    "filters = 16\n",
    "kernel_size = 3\n",
    "\n",
    "latent_inputs = Input(shape=(latent_dimension,), name='z_sampling')\n",
    "decoder = Dense(encoder_shape[1] * encoder_shape[2] * encoder_shape[3], activation='relu')(latent_inputs)\n",
    "decoder = Reshape(encoder_shape[1:])(decoder)\n",
    "for i in range(2):\n",
    "    decoder = Conv2DTranspose(filters=filters,\n",
    "                        kernel_size=kernel_size,\n",
    "                        activation='relu',\n",
    "                        strides=2,\n",
    "                        padding='same')(decoder)\n",
    "    filters //= 2\n",
    "outputs = Conv2DTranspose(filters=1,\n",
    "                          kernel_size=kernel_size,\n",
    "                          activation='sigmoid',\n",
    "                          padding='same',\n",
    "                          name='decoder_output')(decoder)\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = decoder(encoder(input_image)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "vae = Model(input_image, outputs)\n",
    "reconstruction_loss = binary_crossentropy(K.flatten(input_image),\n",
    "                                                  K.flatten(outputs))\n",
    "kl_loss = 1 + z_var - K.square(z_mean) - K.exp(z_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='rmsprop', loss=None)\n",
    "vae.summary()\n",
    "\n",
    "# Train the VAE on MNIST digits\n",
    "(x_train, _), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train = x_train.reshape(x_train.shape + (1,))\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test = x_test.reshape(x_test.shape + (1,))\n",
    "\n",
    "history = vae.fit(x_train,\n",
    "        shuffle=True,\n",
    "        epochs=10,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, None)\n",
    "       )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
